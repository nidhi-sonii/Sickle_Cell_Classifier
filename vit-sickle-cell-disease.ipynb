{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":8166877,"datasetId":4832762,"databundleVersionId":8288971,"isSourceIdPinned":false},{"sourceType":"datasetVersion","sourceId":7883255,"datasetId":3913975,"databundleVersionId":7989282,"isSourceIdPinned":false}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import Compose, ToTensor, Normalize, Resize\nfrom torch import optim\nimport json\nimport random\nfrom PIL import Image\nimport os\nfrom matplotlib import pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:13:39.891188Z","iopub.execute_input":"2025-06-16T07:13:39.891522Z","iopub.status.idle":"2025-06-16T07:13:51.791278Z","shell.execute_reply.started":"2025-06-16T07:13:39.891498Z","shell.execute_reply":"2025-06-16T07:13:51.790289Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"SEED = 97120\nrandom.seed(SEED)\ntorch.manual_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:13:57.582061Z","iopub.execute_input":"2025-06-16T07:13:57.582396Z","iopub.status.idle":"2025-06-16T07:13:57.598991Z","shell.execute_reply.started":"2025-06-16T07:13:57.582371Z","shell.execute_reply":"2025-06-16T07:13:57.598098Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7e76c4fe85b0>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip install pytorch_pretrained_vit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:14:05.700729Z","iopub.execute_input":"2025-06-16T07:14:05.701042Z","iopub.status.idle":"2025-06-16T07:15:47.452747Z","shell.execute_reply.started":"2025-06-16T07:14:05.701020Z","shell.execute_reply":"2025-06-16T07:15:47.451521Z"}},"outputs":[{"name":"stdout","text":"Collecting pytorch_pretrained_vit\n  Downloading pytorch-pretrained-vit-0.0.7.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch_pretrained_vit) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pytorch_pretrained_vit)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->pytorch_pretrained_vit)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->pytorch_pretrained_vit)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->pytorch_pretrained_vit)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pytorch_pretrained_vit)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pytorch_pretrained_vit)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pytorch_pretrained_vit)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_pretrained_vit) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch_pretrained_vit) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch_pretrained_vit) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pytorch_pretrained_vit\n  Building wheel for pytorch_pretrained_vit (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pytorch_pretrained_vit: filename=pytorch_pretrained_vit-0.0.7-py3-none-any.whl size=11115 sha256=75b3b0f97fb47485f19a9757d2f791de73395e3329796dd3c4816d0c732f8972\n  Stored in directory: /root/.cache/pip/wheels/79/c8/4f/9ad72c6f247a7e6888cc7767db9632675cf82656fffec85518\nSuccessfully built pytorch_pretrained_vit\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch_pretrained_vit\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_pretrained_vit-0.0.7\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# import\nfrom pytorch_pretrained_vit import ViT\n\n#- pretrained model\nmodel_name = 'B_16_imagenet1k'\nmodel = ViT(model_name, pretrained=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:15:54.816042Z","iopub.execute_input":"2025-06-16T07:15:54.816336Z","iopub.status.idle":"2025-06-16T07:15:56.949646Z","shell.execute_reply.started":"2025-06-16T07:15:54.816315Z","shell.execute_reply":"2025-06-16T07:15:56.948588Z"}},"outputs":[{"name":"stdout","text":"Loaded pretrained weights.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# SECTION 2: Download Datasets\n# Use kagglehub to download the datasets\nflorencetushabe_path = kagglehub.dataset_download('florencetushabe/sickle-cell-disease-dataset')\nfenicxs_path = kagglehub.dataset_download('fenicxs/sickle-cell-anaemia')\ndata_dir = fenicxs_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:24.792818Z","iopub.execute_input":"2025-06-16T07:16:24.793165Z","iopub.status.idle":"2025-06-16T07:16:24.938274Z","shell.execute_reply.started":"2025-06-16T07:16:24.793143Z","shell.execute_reply":"2025-06-16T07:16:24.937359Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import kagglehub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:17.959625Z","iopub.execute_input":"2025-06-16T07:16:17.959960Z","iopub.status.idle":"2025-06-16T07:16:18.635956Z","shell.execute_reply.started":"2025-06-16T07:16:17.959935Z","shell.execute_reply":"2025-06-16T07:16:18.635011Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport json\nimport random\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:29.727115Z","iopub.execute_input":"2025-06-16T07:16:29.727784Z","iopub.status.idle":"2025-06-16T07:16:29.732312Z","shell.execute_reply.started":"2025-06-16T07:16:29.727756Z","shell.execute_reply":"2025-06-16T07:16:29.731411Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# SECTION 3: Dataset Preparation\n# Define data transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Adjust to ViT input size\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))  # Normalizing images\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:34.685758Z","iopub.execute_input":"2025-06-16T07:16:34.686026Z","iopub.status.idle":"2025-06-16T07:16:34.691534Z","shell.execute_reply.started":"2025-06-16T07:16:34.686008Z","shell.execute_reply":"2025-06-16T07:16:34.690555Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"SEED = 97120\nrandom.seed(SEED)\ntorch.manual_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:38.417432Z","iopub.execute_input":"2025-06-16T07:16:38.417699Z","iopub.status.idle":"2025-06-16T07:16:38.425631Z","shell.execute_reply.started":"2025-06-16T07:16:38.417682Z","shell.execute_reply":"2025-06-16T07:16:38.424708Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7e76c4fe85b0>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:42.531523Z","iopub.execute_input":"2025-06-16T07:16:42.531839Z","iopub.status.idle":"2025-06-16T07:16:43.346106Z","shell.execute_reply.started":"2025-06-16T07:16:42.531818Z","shell.execute_reply":"2025-06-16T07:16:43.345114Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:49.441295Z","iopub.execute_input":"2025-06-16T07:16:49.441608Z","iopub.status.idle":"2025-06-16T07:16:49.446761Z","shell.execute_reply.started":"2025-06-16T07:16:49.441587Z","shell.execute_reply":"2025-06-16T07:16:49.445885Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n# SECTION 4: Define ViT Model\nfrom pytorch_pretrained_vit import ViT","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:53.739065Z","iopub.execute_input":"2025-06-16T07:16:53.739383Z","iopub.status.idle":"2025-06-16T07:16:53.744392Z","shell.execute_reply.started":"2025-06-16T07:16:53.739362Z","shell.execute_reply":"2025-06-16T07:16:53.743601Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model_name = 'B_16_imagenet1k'\nvit = ViT(model_name, pretrained=True)\n\n# Adjust classifier for binary classification\nvit.fc = nn.Linear(vit.fc.in_features, 2) \n\n# Move model to device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nvit = vit.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:16:58.007322Z","iopub.execute_input":"2025-06-16T07:16:58.007664Z","iopub.status.idle":"2025-06-16T07:16:59.925348Z","shell.execute_reply.started":"2025-06-16T07:16:58.007639Z","shell.execute_reply":"2025-06-16T07:16:59.924335Z"}},"outputs":[{"name":"stdout","text":"Loaded pretrained weights.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"#Training and Validation Functions\ndef train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    epoch_loss, correct = 0, 0\n\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        correct += (outputs.argmax(1) == labels).sum().item()\n\n    accuracy = correct / len(dataloader.dataset)\n    return epoch_loss / len(dataloader), accuracy\n\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    epoch_loss, correct = 0, 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            epoch_loss += loss.item()\n            correct += (outputs.argmax(1) == labels).sum().item()\n\n    accuracy = correct / len(dataloader.dataset)\n    return epoch_loss / len(dataloader), accuracy\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:03.864455Z","iopub.execute_input":"2025-06-16T07:17:03.864753Z","iopub.status.idle":"2025-06-16T07:17:03.872547Z","shell.execute_reply.started":"2025-06-16T07:17:03.864735Z","shell.execute_reply":"2025-06-16T07:17:03.871649Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch.nn.functional as F\n\n# Section 6: Adjust positional embeddings\ndef resize_positional_embedding(vit_model, new_grid_size):\n    old_embedding = vit_model.positional_embedding.pos_embedding  # Extract positional embedding\n    cls_token = old_embedding[:, :1]  # Class token\n    old_grid_embedding = old_embedding[:, 1:]  # Grid embeddings\n\n    # Compute old grid size\n    old_grid_size = int(old_grid_embedding.shape[1] ** 0.5)\n    old_grid_embedding = old_grid_embedding.reshape(1, old_grid_size, old_grid_size, -1).permute(0, 3, 1, 2)\n\n    # Resize grid embeddings\n    new_grid_embedding = F.interpolate(\n        old_grid_embedding, size=(new_grid_size, new_grid_size), mode=\"bilinear\", align_corners=False\n    )\n    new_grid_embedding = new_grid_embedding.permute(0, 2, 3, 1).reshape(1, new_grid_size * new_grid_size, -1)\n\n    # Combine class token with resized grid embeddings\n    new_pos_embedding = torch.cat([cls_token, new_grid_embedding], dim=1)\n    vit_model.positional_embedding.pos_embedding = torch.nn.Parameter(new_pos_embedding)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:09.036784Z","iopub.execute_input":"2025-06-16T07:17:09.037084Z","iopub.status.idle":"2025-06-16T07:17:09.043823Z","shell.execute_reply.started":"2025-06-16T07:17:09.037061Z","shell.execute_reply":"2025-06-16T07:17:09.042568Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"resize_positional_embedding(vit, new_grid_size=14)\nprint(f\"Resized positional embedding shape: {vit.positional_embedding.pos_embedding.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:13.940296Z","iopub.execute_input":"2025-06-16T07:17:13.940575Z","iopub.status.idle":"2025-06-16T07:17:13.977933Z","shell.execute_reply.started":"2025-06-16T07:17:13.940558Z","shell.execute_reply":"2025-06-16T07:17:13.976969Z"}},"outputs":[{"name":"stdout","text":"Resized positional embedding shape: torch.Size([1, 197, 768])\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:19.036990Z","iopub.execute_input":"2025-06-16T07:17:19.037351Z","iopub.status.idle":"2025-06-16T07:17:19.042830Z","shell.execute_reply.started":"2025-06-16T07:17:19.037327Z","shell.execute_reply":"2025-06-16T07:17:19.041878Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"for images, _ in train_loader:\n    images = images.to(device)\n    patch_embeddings = vit.patch_embedding(images)\n    print(f\"Patch embedding shape: {patch_embeddings.shape}\")\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:22.965211Z","iopub.execute_input":"2025-06-16T07:17:22.965555Z","iopub.status.idle":"2025-06-16T07:17:25.068051Z","shell.execute_reply.started":"2025-06-16T07:17:22.965531Z","shell.execute_reply":"2025-06-16T07:17:25.067269Z"}},"outputs":[{"name":"stdout","text":"Patch embedding shape: torch.Size([32, 768, 14, 14])\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\nbatch_size, hidden_size, grid_h, grid_w = patch_embeddings.shape\npatch_embeddings = patch_embeddings.view(batch_size, hidden_size, -1).permute(0, 2, 1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:27.800996Z","iopub.execute_input":"2025-06-16T07:17:27.801754Z","iopub.status.idle":"2025-06-16T07:17:27.806621Z","shell.execute_reply.started":"2025-06-16T07:17:27.801724Z","shell.execute_reply":"2025-06-16T07:17:27.805595Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#Prepare for training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nvit = vit.to(device)\n\noptimizer = torch.optim.Adam(vit.parameters(), lr=0.0001)\ncriterion = torch.nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:32.103061Z","iopub.execute_input":"2025-06-16T07:17:32.103392Z","iopub.status.idle":"2025-06-16T07:17:32.114533Z","shell.execute_reply.started":"2025-06-16T07:17:32.103368Z","shell.execute_reply":"2025-06-16T07:17:32.113604Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Define training and validation functions\ndef train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss, total_correct = 0, 0\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        total_correct += (outputs.argmax(1) == labels).sum().item()\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = total_correct / len(dataloader.dataset)\n    return avg_loss, accuracy\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    total_loss, total_correct = 0, 0\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            total_loss += loss.item()\n            total_correct += (outputs.argmax(1) == labels).sum().item()\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = total_correct / len(dataloader.dataset)\n    return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:17:35.957294Z","iopub.execute_input":"2025-06-16T07:17:35.957622Z","iopub.status.idle":"2025-06-16T07:17:35.965316Z","shell.execute_reply.started":"2025-06-16T07:17:35.957600Z","shell.execute_reply":"2025-06-16T07:17:35.964614Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Section 9: Training loop\nepochs = 10\nfor epoch in range(epochs):\n    train_loss, train_acc = train_epoch(vit, train_loader, optimizer, criterion, device)\n    val_loss, val_acc = validate_epoch(vit, val_loader, criterion, device)\n    print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.4011, Train Acc: 0.8418 - Val Loss: 0.5147, Val Acc: 0.8421\nEpoch 2/10 - Train Loss: 0.2443, Train Acc: 0.9121 - Val Loss: 0.3878, Val Acc: 0.8596\nEpoch 3/10 - Train Loss: 0.1816, Train Acc: 0.9209 - Val Loss: 0.6924, Val Acc: 0.7719\nEpoch 4/10 - Train Loss: 0.1267, Train Acc: 0.9538 - Val Loss: 0.4328, Val Acc: 0.8947\nEpoch 5/10 - Train Loss: 0.1805, Train Acc: 0.9231 - Val Loss: 0.5188, Val Acc: 0.8684\nEpoch 6/10 - Train Loss: 0.1133, Train Acc: 0.9604 - Val Loss: 0.4526, Val Acc: 0.8421\nEpoch 7/10 - Train Loss: 0.1327, Train Acc: 0.9516 - Val Loss: 0.5395, Val Acc: 0.9035\nEpoch 8/10 - Train Loss: 0.0881, Train Acc: 0.9736 - Val Loss: 0.4324, Val Acc: 0.8333\nEpoch 9/10 - Train Loss: 0.0697, Train Acc: 0.9780 - Val Loss: 0.4409, Val Acc: 0.8860\nEpoch 10/10 - Train Loss: 0.0231, Train Acc: 0.9934 - Val Loss: 0.4013, Val Acc: 0.9123\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Save the trained model\ntorch.save(vit.state_dict(), \"vit_sickle_cell_classifier.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T09:59:43.758907Z","iopub.execute_input":"2025-06-16T09:59:43.759289Z","iopub.status.idle":"2025-06-16T09:59:44.421970Z","shell.execute_reply.started":"2025-06-16T09:59:43.759256Z","shell.execute_reply":"2025-06-16T09:59:44.421063Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import random_split, DataLoader\n\n# SECTION 2: Download Datasets\n# Use kagglehub to download the datasets\nflorencetushabe_path = kagglehub.dataset_download('florencetushabe/sickle-cell-disease-dataset')\nfenicxs_path = kagglehub.dataset_download('fenicxs/sickle-cell-anaemia')\ndata_dir = fenicxs_path\n\n# Define the data transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to match ViT input size\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalization\n])\n\n# Load the full dataset\nfull_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n\n# Split the dataset into training, validation, and test sets\ntrain_size = int(0.7 * len(full_dataset))\nval_size = int(0.2 * len(full_dataset))\ntest_size = len(full_dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n\n# Create DataLoaders\nbatch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nprint(f\"Train dataset size: {len(train_dataset)} samples\")\nprint(f\"Validation dataset size: {len(val_dataset)} samples\")\nprint(f\"Test dataset size: {len(test_dataset)} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T10:01:50.455452Z","iopub.execute_input":"2025-06-16T10:01:50.455839Z","iopub.status.idle":"2025-06-16T10:01:51.887074Z","shell.execute_reply.started":"2025-06-16T10:01:50.455813Z","shell.execute_reply":"2025-06-16T10:01:51.886265Z"}},"outputs":[{"name":"stdout","text":"Train dataset size: 398 samples\nValidation dataset size: 113 samples\nTest dataset size: 58 samples\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"test_loss, test_acc = validate_epoch(vit, test_loader, criterion, device)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T10:02:03.093309Z","iopub.execute_input":"2025-06-16T10:02:03.093632Z","iopub.status.idle":"2025-06-16T10:02:23.787494Z","shell.execute_reply.started":"2025-06-16T10:02:03.093607Z","shell.execute_reply":"2025-06-16T10:02:23.786512Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.1959, Test Accuracy: 0.9483\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Section 10: Test Function\ndef test_model(model, dataloader, criterion, device):\n    model.eval()  # Set model to evaluation mode\n    test_loss = 0.0\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():  # No gradients required during testing\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            \n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n\n            # Get predictions and calculate accuracy\n            _, preds = torch.max(outputs, 1)\n            correct_predictions += (preds == labels).sum().item()\n            total_predictions += labels.size(0)\n\n    # Calculate average loss and accuracy\n    avg_loss = test_loss / len(dataloader)\n    accuracy = correct_predictions / total_predictions\n    return avg_loss, accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T10:08:28.492572Z","iopub.execute_input":"2025-06-16T10:08:28.492935Z","iopub.status.idle":"2025-06-16T10:08:28.500299Z","shell.execute_reply.started":"2025-06-16T10:08:28.492911Z","shell.execute_reply":"2025-06-16T10:08:28.499256Z"}},"outputs":[],"execution_count":41}]}